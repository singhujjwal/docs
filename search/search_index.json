{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quick reference DEVOPS Cloud K8s Linux Quick Commands","title":"Home"},{"location":"#quick-reference","text":"","title":"Quick reference"},{"location":"#devops","text":"","title":"DEVOPS"},{"location":"#cloud","text":"","title":"Cloud"},{"location":"#k8s","text":"","title":"K8s"},{"location":"#linux","text":"","title":"Linux"},{"location":"#quick-commands","text":"","title":"Quick Commands"},{"location":"cloud/","text":"Services Compute EC2 is the compute service on AWS Storage SOFTNAS usage on AWS Role is very important and the policy { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"aws-marketplace:MeterUsage\", \"ec2:ModifyInstanceAttribute\", \"ec2:DescribeInstances\", \"ec2:CreateVolume\", \"ec2:DeleteVolume\", \"ec2:CreateSnapshot\", \"ec2:DeleteSnapshot\", \"ec2:CreateTags\", \"ec2:DeleteTags\", \"ec2:AttachVolume\", \"ec2:DetachVolume\", \"ec2:DescribeInstances\", \"ec2:DescribeVolumes\", \"ec2:DescribeSnapshots\", \"ec2:DescribeRouteTables\", \"ec2:DescribeAddresses\", \"ec2:DescribeTags\", \"ec2:DescribeInstances\", \"ec2:ModifyNetworkInterfaceAttribute\", \"ec2:ReplaceRoute\", \"ec2:CreateRoute\", \"ec2:DeleteRoute\", \"ec2:AssociateAddress\", \"ec2:DisassociateAddress\", \"s3:CreateBucket\", \"s3:Delete*\", \"s3:Get*\", \"s3:List*\", \"s3:Put*\" ], \"Resource\": \"*\" } ] } AZURE Account and Subscription Your company has an account and you get access to the portal.azure.com but if you don't have a subscription, you can't do anything. In that case either you need to be assigned to a subscription or a tenant or you should have an owner role to create a subscription in that account. The account can be alternatively be called as tenant. Here is a link that describe all types of roles in Azure Directory -> tenant -> Subscriptions (I see one subscription in one directory account is company account) This defines a role is constructed using json, the similar way AWS IAM policies work. Policies link","title":"Cloud"},{"location":"cloud/#services","text":"","title":"Services"},{"location":"cloud/#compute","text":"EC2 is the compute service on AWS","title":"Compute"},{"location":"cloud/#storage","text":"","title":"Storage"},{"location":"cloud/#softnas-usage-on-aws","text":"Role is very important and the policy { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"aws-marketplace:MeterUsage\", \"ec2:ModifyInstanceAttribute\", \"ec2:DescribeInstances\", \"ec2:CreateVolume\", \"ec2:DeleteVolume\", \"ec2:CreateSnapshot\", \"ec2:DeleteSnapshot\", \"ec2:CreateTags\", \"ec2:DeleteTags\", \"ec2:AttachVolume\", \"ec2:DetachVolume\", \"ec2:DescribeInstances\", \"ec2:DescribeVolumes\", \"ec2:DescribeSnapshots\", \"ec2:DescribeRouteTables\", \"ec2:DescribeAddresses\", \"ec2:DescribeTags\", \"ec2:DescribeInstances\", \"ec2:ModifyNetworkInterfaceAttribute\", \"ec2:ReplaceRoute\", \"ec2:CreateRoute\", \"ec2:DeleteRoute\", \"ec2:AssociateAddress\", \"ec2:DisassociateAddress\", \"s3:CreateBucket\", \"s3:Delete*\", \"s3:Get*\", \"s3:List*\", \"s3:Put*\" ], \"Resource\": \"*\" } ] }","title":"SOFTNAS usage on AWS"},{"location":"cloud/#azure","text":"","title":"AZURE"},{"location":"cloud/#account-and-subscription","text":"Your company has an account and you get access to the portal.azure.com but if you don't have a subscription, you can't do anything. In that case either you need to be assigned to a subscription or a tenant or you should have an owner role to create a subscription in that account. The account can be alternatively be called as tenant. Here is a link that describe all types of roles in Azure Directory -> tenant -> Subscriptions (I see one subscription in one directory account is company account) This defines a role is constructed using json, the similar way AWS IAM policies work.","title":"Account and Subscription"},{"location":"cloud/#policies-link","text":"","title":"Policies link"},{"location":"commands/","text":"Quick Reference Commands GIT Revert a PR git checkout <branch> git pull git log now switch to another branch gco -b revert-pr git revert -m 1 <SHA-1> git push Revert local commit Revert last commit git reset --hard HEAD~1 Revert last 5 commits git reset --hard HEAD~5 Revert commits but keep content git reset --soft HEAD~1 Delete a specific commit git reset --hard <sha1-commit-hash>","title":"Commands"},{"location":"commands/#quick-reference-commands","text":"","title":"Quick Reference Commands"},{"location":"commands/#git","text":"","title":"GIT"},{"location":"commands/#revert-a-pr","text":"git checkout <branch> git pull git log now switch to another branch gco -b revert-pr git revert -m 1 <SHA-1> git push","title":"Revert a PR"},{"location":"commands/#revert-local-commit","text":"","title":"Revert local commit"},{"location":"commands/#revert-last-commit","text":"git reset --hard HEAD~1","title":"Revert last commit"},{"location":"commands/#revert-last-5-commits","text":"git reset --hard HEAD~5","title":"Revert last 5 commits"},{"location":"commands/#revert-commits-but-keep-content","text":"git reset --soft HEAD~1","title":"Revert commits but keep content"},{"location":"commands/#delete-a-specific-commit","text":"git reset --hard <sha1-commit-hash>","title":"Delete a specific commit"},{"location":"containers/","text":"Containers Docker Containerd rocket Container Runtime OCI Open Container Interface - Standard for containers Docker containerd(image management)-runc(runtime management) docker daemon -> containerd -> runc In K8s how docker and containerd works kubelet <-CRI-> docker shim <-> docker <-> containerd <-> runc <-> container(s) kubelet <-CRI-> cri-containerd <-> containerd <-> runc <-> container(s) containerd - push and pull images - manage storage - define networks - managing lifecycle of running containers by passing commands to runc runc - also known as libcontainer - low level run time - Rocket (rkt) -- Dead Linux containers (lxc & lxd) VE vs VM running directly on the host VM More reading","title":"Containers"},{"location":"containers/#containers","text":"Docker Containerd rocket Container Runtime OCI Open Container Interface - Standard for containers","title":"Containers"},{"location":"containers/#docker","text":"containerd(image management)-runc(runtime management) docker daemon -> containerd -> runc In K8s how docker and containerd works kubelet <-CRI-> docker shim <-> docker <-> containerd <-> runc <-> container(s) kubelet <-CRI-> cri-containerd <-> containerd <-> runc <-> container(s) containerd - push and pull images - manage storage - define networks - managing lifecycle of running containers by passing commands to runc runc - also known as libcontainer - low level run time - Rocket (rkt) -- Dead Linux containers (lxc & lxd) VE vs VM running directly on the host VM More reading","title":"Docker"},{"location":"interviewquestions/","text":"Interview questions What is DevOps how do you devops ? What is a microservice and what are the advantages of it over monolithic Why REST ? How streaming services works design a messaging system. Why you\u2019re passionate about being an engineering manager at xxx in particular. How you approach engineering management. The team you\u2019re most proud of supporting, and your role in helping it succeed. Time series database design X = (t,v,q) [ ] Most of the time every data point is handled as a new entry instead of as an update for already saved data entry [ ] time series data usually is in time order when it arrives. [ ] third characteristic is time indexed data, making time the primary axis for the data [ ] Timestamp and k.v(Integer, String, floats and booleans) [*] InfluxQL is SQL like language Elasticsearch support near real-time reading which allows it to be used as NoSQL database. Elasticsearch uses JSON formatted documents as it datatypes which allow users to create their own data schema. As Elasticsearch is mainly a search and analytics engine, it has support for extended querying with multiple aggregating, filtering, and indexing functions. Data can be accessed through the REST API. Elasticsearch support scalability to multiple nodes and replication. . Scalability . Security . Availability . Performance Databases [*] Postgres link /usr/lib/postgresql/10/bin/pg_ctl -D /var/lib/postgresql/10/main -l logfile start Add user createuser --interactive --pwprompt Add database createdb movies System Design interviews Loadbalancer Software LoadBalancer Hardware Loadbalancer Loadbalancing algortithms [ ] Round Robin \u2013 Requests are distributed across the group of servers sequentially. [ ] Least Connections \u2013 A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections. [ ] Least Time \u2013 Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections. [ ] Hash \u2013 Distributes requests based on a key you define, such as the client IP address or the request URL. [ ] IP Hash \u2013 The IP address of the client is used to determine which server receives the request. [ ] Random with Two Choices \u2013 Picks two servers at random and sends the request to the one that is selected by then applying the Least Connections algorithm (or for NGINX Plus the Least Time algorithm, if so configured). Session Persistence or Stickieness - > Two options either determined through the hash function which calculates hash based on the browser saved cookies else stores the data locally at the load balancer. L7 vs L4 Load balancing L7 is more CPU intensive as it has to do more processing till the packet reaches application layer rather at networking level.","title":"Interviewquestions"},{"location":"interviewquestions/#interview-questions","text":"What is DevOps how do you devops ? What is a microservice and what are the advantages of it over monolithic Why REST ? How streaming services works design a messaging system. Why you\u2019re passionate about being an engineering manager at xxx in particular. How you approach engineering management. The team you\u2019re most proud of supporting, and your role in helping it succeed.","title":"Interview questions"},{"location":"interviewquestions/#time-series-database-design","text":"X = (t,v,q) [ ] Most of the time every data point is handled as a new entry instead of as an update for already saved data entry [ ] time series data usually is in time order when it arrives. [ ] third characteristic is time indexed data, making time the primary axis for the data [ ] Timestamp and k.v(Integer, String, floats and booleans) [*] InfluxQL is SQL like language Elasticsearch support near real-time reading which allows it to be used as NoSQL database. Elasticsearch uses JSON formatted documents as it datatypes which allow users to create their own data schema. As Elasticsearch is mainly a search and analytics engine, it has support for extended querying with multiple aggregating, filtering, and indexing functions. Data can be accessed through the REST API. Elasticsearch support scalability to multiple nodes and replication. . Scalability . Security . Availability . Performance","title":"Time series database design"},{"location":"interviewquestions/#databases","text":"[*] Postgres link /usr/lib/postgresql/10/bin/pg_ctl -D /var/lib/postgresql/10/main -l logfile start","title":"Databases"},{"location":"interviewquestions/#add-user","text":"createuser --interactive --pwprompt Add database createdb movies","title":"Add user"},{"location":"interviewquestions/#system-design-interviews","text":"","title":"System Design interviews"},{"location":"interviewquestions/#loadbalancer","text":"Software LoadBalancer Hardware Loadbalancer","title":"Loadbalancer"},{"location":"interviewquestions/#loadbalancing-algortithms","text":"[ ] Round Robin \u2013 Requests are distributed across the group of servers sequentially. [ ] Least Connections \u2013 A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections. [ ] Least Time \u2013 Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections. [ ] Hash \u2013 Distributes requests based on a key you define, such as the client IP address or the request URL. [ ] IP Hash \u2013 The IP address of the client is used to determine which server receives the request. [ ] Random with Two Choices \u2013 Picks two servers at random and sends the request to the one that is selected by then applying the Least Connections algorithm (or for NGINX Plus the Least Time algorithm, if so configured). Session Persistence or Stickieness - > Two options either determined through the hash function which calculates hash based on the browser saved cookies else stores the data locally at the load balancer. L7 vs L4 Load balancing L7 is more CPU intensive as it has to do more processing till the packet reaches application layer rather at networking level.","title":"Loadbalancing algortithms"},{"location":"k8s/","text":"Kubernetes Concepts Concepts The best resource for learning kubernetes concepts is the kubernetes reference docs. I will try to be concise here and will be mostly including relevant links as managing those links in the bookmarks folder becomes unmanageable and putting the duplicate material is a waste of time and doesnt give the due respect to the original authors. Concepts I will be putting stuffs down, which I think I keep forgetting A loadbalancer is exteneded type of nodeport service where an external loadbalancer is created based on the cloud provider. A loadbalancer will have a port mapping for the port LB is listening to the target port and the service name Tcp can be patched to the nginx ingress controller loadbalancer by creating a config map and telling where in which namespace which service on which port to hit. e.g. apiVersion: v1 kind: Service metadata: name: tcp-echo labels: app: tcp-echo spec: ports: - name: tcp port: 9000 selector: app: tcp-echo --- apiVersion: apps/v1 kind: Deployment metadata: name: tcp-echo spec: replicas: 1 selector: matchLabels: app: tcp-echo version: v1 template: metadata: labels: app: tcp-echo version: v1 spec: containers: - name: tcp-echo image: docker.io/istio/tcp-echo-server:1.1 imagePullPolicy: IfNotPresent args: [ \"9000\", \"hello\" ] ports: - containerPort: 9000 Below created the config map nginx-ingress-tcp while creating nginx load balancer --set tcp.9000=\"my-system/tcp-echo:9000\" \\ Also you can have now mostly all internal load balancers and for external load balancers use WAF for better security the WAF will be communicating with the internal load balancers and will figure out how TLS/SSL certificates now work in addition to cert-manager. Volumes Types of volumes Local EBS azureDisk azureFile configMap emptyDir hostPath local nfs persistentVolumeClaim Persistent Volume A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system. Persistent Volume Claim A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted once read/write or many times read-only). It can be static of dynamic, if a cluster admin has not created a PV explicitly a dynamic PV is created when a PVC is requested. Few Commands Print the kubelet joinging command: sudo kubeadm token create --print-join-command kubelet reset # to reset a node joined to a master, also from master it can be deleted like kubectl delete node # https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/ kubectl port-forward pods/redis-master-765d459796-258hz 6379:6379 or kubectl port-forward deployment/redis-master 6379:6379 or kubectl port-forward rs/redis-master 6379:6379 or kubectl port-forward svc/redis-master 6379:6379 K8s Install on CENTOS sudo swapoff -a sudo vi /etc/fstab sudo yum -y install docker sudo systemctl enable docker sudo systemctl start docker cat << EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo setenforce 0 sudo vi /etc/selinux/config # Change to permissive sudo yum install -y kubelet kubeadm kubectl sudo systemctl enable kubelet sudo systemctl start kubelet cat << EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system #Only on master sudo kubeadm init --pod-network-cidr=10.244.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # Check for right flannel # kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # only on worker nodes sudo kubeadm join $controller_private_ip:6443 --token $token --discovery-token-ca-cert-hash $hash sudo kubeadm join 172.31.100.147:6443 --token w28oiv.2dx6buwbj400mc4x --discovery-token-ca-cert-hash sha256:ed0e354f71183a76cbb58166d5d710b3b39e343c253ee232509ce5f412d05b3a kubectl get nodes Securing Persistent Key Value Store or SECRETS in k8s kubectl get secrets kubectl run pod-with-defaults --image alpine --restart Never -- /bin/sleep 999999 kubectl describe pods pod-with-defaults kubectl exec pod id kubectl describe secret openssl genrsa -out https.key 2048 openssl req -new -x509 -key https.key -out https.cert -days 3650 -subj /CN=www.example.com touch file kubectl create secret generic example-https --from-file=https.key --from-file=https.cert --from-file=file kubectl get secrets example-https -o yaml nginx.conf ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: config data: my-nginx-config.conf: | server { listen 80; listen 443 ssl; server_name www.example.com; ssl_certificate certs/https.cert; ssl_certificate_key certs/https.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { root /usr/share/nginx/html; index index.html index.htm; } } sleep-interval: | 25 example-https.yaml apiVersion: v1 kind: Pod metadata: name: example-https spec: containers: - image: linuxacademycontent/fortune name: html-web env: - name: INTERVAL valueFrom: configMapKeyRef: name: config key: sleep-interval volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true - name: config mountPath: /etc/nginx/conf.d readOnly: true - name: certs mountPath: /etc/nginx/certs/ readOnly: true ports: - containerPort: 80 - containerPort: 443 volumes: - name: html emptyDir: {} - name: config configMap: name: config items: - key: my-nginx-config.conf path: https.conf - name: certs secret: secretName: example-https kubectl exec example-https -c web-server -- mount | grep certs kubectl port-forward example-https 8443:443 & curl https://localhost:8443 -k Cert-Manager Cert manager is a very important package for generating certs for applications in k8s. DNS01 challenge are very helpful in creating wildcard certificates, also http01 challenges are good when you want just few certs There are many gotchas and need to have either a role, cross account role for AWS For azure use the service principal. Also for split horizon dns cert-manager can be run using parameter extraArgs={--dns01-recursive-nameservers \"8.8.8.8:53,1.1.1.1:53\"} https://cert-manager.io/docs/configuration/acme/dns01/ Steps to use cert-manager 1. Install cert-manager CRDS 2. Install cert-manager with the extra dns options in case of split horizon or delegated DNS 3. Create a certificate issuer in cert-manager namespace based on the CRD apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-staging namespace: cert-manager spec: acme: # server: https://acme-staging-v02.api.letsencrypt.org/directory server: https://acme-v02.api.letsencrypt.org/directory email: ujjwal.singh@example.com privateKeySecretRef: name: letsencrypt-staging solvers: - selector: dnsZones: - \"tenant1.example.com\" dns01: route53: region: us-east-1 hostedZoneID: xxxxxxxxxxxx role: 'arn:aws:iam::xxxxxxxxxx:role/Role-DNS-STS' Create the certificate in the namespace where you want to use the tls secret, else you need to copy the tls secret to all the namespaces if the ingress needs to be created in another namespace apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: lets-encrypt-cert namespace: ict spec: commonName: 'ujjwal.tenant1.example.com' dnsNames: - '*.ujjwal.tenant1.example.com' - 'ujjwal.tenant1.example.com' issuerRef: kind: ClusterIssuer name: letsencrypt-staging secretName: letsencrypt-staging-cert-secret Create an ingress which loads the tls certs apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress namespace: ict annotations: kubernetes.io/ingress.class: traefik spec: tls: - secretName: letsencrypt-staging-cert-secret rules: - host: ujjwal.tenant1.example.com http: paths: - path: /awx backend: serviceName: awx servicePort: 8052 # The node port You can use https://github.com/mittwald/kubernetes-replicator for replicating secrets across namespaces.","title":"K8S Concepts"},{"location":"k8s/#kubernetes-concepts","text":"","title":"Kubernetes Concepts"},{"location":"k8s/#concepts","text":"The best resource for learning kubernetes concepts is the kubernetes reference docs. I will try to be concise here and will be mostly including relevant links as managing those links in the bookmarks folder becomes unmanageable and putting the duplicate material is a waste of time and doesnt give the due respect to the original authors. Concepts I will be putting stuffs down, which I think I keep forgetting A loadbalancer is exteneded type of nodeport service where an external loadbalancer is created based on the cloud provider. A loadbalancer will have a port mapping for the port LB is listening to the target port and the service name Tcp can be patched to the nginx ingress controller loadbalancer by creating a config map and telling where in which namespace which service on which port to hit. e.g. apiVersion: v1 kind: Service metadata: name: tcp-echo labels: app: tcp-echo spec: ports: - name: tcp port: 9000 selector: app: tcp-echo --- apiVersion: apps/v1 kind: Deployment metadata: name: tcp-echo spec: replicas: 1 selector: matchLabels: app: tcp-echo version: v1 template: metadata: labels: app: tcp-echo version: v1 spec: containers: - name: tcp-echo image: docker.io/istio/tcp-echo-server:1.1 imagePullPolicy: IfNotPresent args: [ \"9000\", \"hello\" ] ports: - containerPort: 9000 Below created the config map nginx-ingress-tcp while creating nginx load balancer --set tcp.9000=\"my-system/tcp-echo:9000\" \\ Also you can have now mostly all internal load balancers and for external load balancers use WAF for better security the WAF will be communicating with the internal load balancers and will figure out how TLS/SSL certificates now work in addition to cert-manager.","title":"Concepts"},{"location":"k8s/#volumes","text":"Types of volumes Local EBS azureDisk azureFile configMap emptyDir hostPath local nfs persistentVolumeClaim","title":"Volumes"},{"location":"k8s/#persistent-volume","text":"A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.","title":"Persistent Volume"},{"location":"k8s/#persistent-volume-claim","text":"A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted once read/write or many times read-only). It can be static of dynamic, if a cluster admin has not created a PV explicitly a dynamic PV is created when a PVC is requested.","title":"Persistent Volume Claim"},{"location":"k8s/#few-commands","text":"Print the kubelet joinging command: sudo kubeadm token create --print-join-command kubelet reset # to reset a node joined to a master, also from master it can be deleted like kubectl delete node # https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/ kubectl port-forward pods/redis-master-765d459796-258hz 6379:6379 or kubectl port-forward deployment/redis-master 6379:6379 or kubectl port-forward rs/redis-master 6379:6379 or kubectl port-forward svc/redis-master 6379:6379","title":"Few Commands"},{"location":"k8s/#k8s-install-on-centos","text":"sudo swapoff -a sudo vi /etc/fstab sudo yum -y install docker sudo systemctl enable docker sudo systemctl start docker cat << EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo setenforce 0 sudo vi /etc/selinux/config # Change to permissive sudo yum install -y kubelet kubeadm kubectl sudo systemctl enable kubelet sudo systemctl start kubelet cat << EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system #Only on master sudo kubeadm init --pod-network-cidr=10.244.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # Check for right flannel # kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # only on worker nodes sudo kubeadm join $controller_private_ip:6443 --token $token --discovery-token-ca-cert-hash $hash sudo kubeadm join 172.31.100.147:6443 --token w28oiv.2dx6buwbj400mc4x --discovery-token-ca-cert-hash sha256:ed0e354f71183a76cbb58166d5d710b3b39e343c253ee232509ce5f412d05b3a kubectl get nodes","title":"K8s Install on CENTOS"},{"location":"k8s/#securing-persistent-key-value-store-or-secrets-in-k8s","text":"kubectl get secrets kubectl run pod-with-defaults --image alpine --restart Never -- /bin/sleep 999999 kubectl describe pods pod-with-defaults kubectl exec pod id kubectl describe secret openssl genrsa -out https.key 2048 openssl req -new -x509 -key https.key -out https.cert -days 3650 -subj /CN=www.example.com touch file kubectl create secret generic example-https --from-file=https.key --from-file=https.cert --from-file=file kubectl get secrets example-https -o yaml nginx.conf ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: config data: my-nginx-config.conf: | server { listen 80; listen 443 ssl; server_name www.example.com; ssl_certificate certs/https.cert; ssl_certificate_key certs/https.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { root /usr/share/nginx/html; index index.html index.htm; } } sleep-interval: | 25 example-https.yaml apiVersion: v1 kind: Pod metadata: name: example-https spec: containers: - image: linuxacademycontent/fortune name: html-web env: - name: INTERVAL valueFrom: configMapKeyRef: name: config key: sleep-interval volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true - name: config mountPath: /etc/nginx/conf.d readOnly: true - name: certs mountPath: /etc/nginx/certs/ readOnly: true ports: - containerPort: 80 - containerPort: 443 volumes: - name: html emptyDir: {} - name: config configMap: name: config items: - key: my-nginx-config.conf path: https.conf - name: certs secret: secretName: example-https kubectl exec example-https -c web-server -- mount | grep certs kubectl port-forward example-https 8443:443 & curl https://localhost:8443 -k","title":"Securing Persistent Key Value Store or SECRETS in k8s"},{"location":"k8s/#cert-manager","text":"Cert manager is a very important package for generating certs for applications in k8s. DNS01 challenge are very helpful in creating wildcard certificates, also http01 challenges are good when you want just few certs There are many gotchas and need to have either a role, cross account role for AWS For azure use the service principal. Also for split horizon dns cert-manager can be run using parameter extraArgs={--dns01-recursive-nameservers \"8.8.8.8:53,1.1.1.1:53\"} https://cert-manager.io/docs/configuration/acme/dns01/ Steps to use cert-manager 1. Install cert-manager CRDS 2. Install cert-manager with the extra dns options in case of split horizon or delegated DNS 3. Create a certificate issuer in cert-manager namespace based on the CRD apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-staging namespace: cert-manager spec: acme: # server: https://acme-staging-v02.api.letsencrypt.org/directory server: https://acme-v02.api.letsencrypt.org/directory email: ujjwal.singh@example.com privateKeySecretRef: name: letsencrypt-staging solvers: - selector: dnsZones: - \"tenant1.example.com\" dns01: route53: region: us-east-1 hostedZoneID: xxxxxxxxxxxx role: 'arn:aws:iam::xxxxxxxxxx:role/Role-DNS-STS' Create the certificate in the namespace where you want to use the tls secret, else you need to copy the tls secret to all the namespaces if the ingress needs to be created in another namespace apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: lets-encrypt-cert namespace: ict spec: commonName: 'ujjwal.tenant1.example.com' dnsNames: - '*.ujjwal.tenant1.example.com' - 'ujjwal.tenant1.example.com' issuerRef: kind: ClusterIssuer name: letsencrypt-staging secretName: letsencrypt-staging-cert-secret Create an ingress which loads the tls certs apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress namespace: ict annotations: kubernetes.io/ingress.class: traefik spec: tls: - secretName: letsencrypt-staging-cert-secret rules: - host: ujjwal.tenant1.example.com http: paths: - path: /awx backend: serviceName: awx servicePort: 8052 # The node port You can use https://github.com/mittwald/kubernetes-replicator for replicating secrets across namespaces.","title":"Cert-Manager"},{"location":"linux/","text":"Bash Scripting Update code present Command to pull all the code from master branch in all the subdirectories in a code folder for d in $(find -maxdepth 1 -type d) do pushd $d git pull popd done Setting proxy for updates Ubuntu cat /etc/apt/apt.conf Acquire::http::Proxy \"http://proxy.example.com:80\"; Acquire::ftp::Proxy \"https://proxy.example.com:80\"; Acquire::https::Proxy \"http://proxy.example.com:80\"; Troubleshooting Networking use either telnet or ncat nc -vvvzw1 google.com 443 nc is part of bind tools wget https://github.com/tmate-io/tmate/releases/download/2.4.0/tmate-2.4.0-static-linux-amd64.tar.xz chmod +x ./tmate xz -cd te-2.4.0-static-linux-amd64.tar.xz | t ./tmate -F Linux Debugging Linux debugging is nothing without knowing the right commands. That too in quick time. Debugging Linux falls into various categories * System diagnostics: Devices, CPU, memory, IO, networking * Logs * Processes * Inspecting filesystem and open files * Sockets and networking * System Diagonostics top mpstat sar # install using apt-get install sysstat Cron job present here cat /etc/cron.d/sysstat sar between 10AM-12 AM sar -r -s 10:00:00 -e 12:00:00 sar on 10th of the month sar -f /var/log/sysstat/sa10 -b File systems volumes external internal attaching detaching blah blah cloud_init tmpfs is the temporary file system in-memory similar as RAM cgroup Logs There are various log files generated in Linux system which will help debugging the errors. journalctl journalctl is a command for viewing logs collected by systemd. The systemd-journald service is responsible for systemd\u2019s log collection, and it retrieves messages from the kernel, systemd services, and other sources. journalctl -r journalctl -u telegraf --no-pager -f to see all the logs without paging and following the running logs persist logs by making changes here /etc/systemd/journald.conf","title":"Linux"},{"location":"linux/#bash-scripting","text":"","title":"Bash Scripting"},{"location":"linux/#update-code-present","text":"Command to pull all the code from master branch in all the subdirectories in a code folder for d in $(find -maxdepth 1 -type d) do pushd $d git pull popd done","title":"Update code present"},{"location":"linux/#setting-proxy-for-updates","text":"","title":"Setting proxy for updates"},{"location":"linux/#ubuntu","text":"cat /etc/apt/apt.conf Acquire::http::Proxy \"http://proxy.example.com:80\"; Acquire::ftp::Proxy \"https://proxy.example.com:80\"; Acquire::https::Proxy \"http://proxy.example.com:80\";","title":"Ubuntu"},{"location":"linux/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"linux/#networking","text":"use either telnet or ncat nc -vvvzw1 google.com 443 nc is part of bind tools wget https://github.com/tmate-io/tmate/releases/download/2.4.0/tmate-2.4.0-static-linux-amd64.tar.xz chmod +x ./tmate xz -cd te-2.4.0-static-linux-amd64.tar.xz | t ./tmate -F","title":"Networking"},{"location":"linux/#linux-debugging","text":"Linux debugging is nothing without knowing the right commands. That too in quick time. Debugging Linux falls into various categories * System diagnostics: Devices, CPU, memory, IO, networking * Logs * Processes * Inspecting filesystem and open files * Sockets and networking *","title":"Linux Debugging"},{"location":"linux/#system-diagonostics","text":"top mpstat sar # install using apt-get install sysstat Cron job present here cat /etc/cron.d/sysstat sar between 10AM-12 AM sar -r -s 10:00:00 -e 12:00:00 sar on 10th of the month sar -f /var/log/sysstat/sa10 -b","title":"System Diagonostics"},{"location":"linux/#file-systems-volumes-external-internal-attaching-detaching-blah-blah-cloud_init","text":"tmpfs is the temporary file system in-memory similar as RAM cgroup","title":"File systems volumes external internal attaching detaching blah blah cloud_init"},{"location":"linux/#logs","text":"There are various log files generated in Linux system which will help debugging the errors.","title":"Logs"},{"location":"linux/#journalctl","text":"journalctl is a command for viewing logs collected by systemd. The systemd-journald service is responsible for systemd\u2019s log collection, and it retrieves messages from the kernel, systemd services, and other sources. journalctl -r journalctl -u telegraf --no-pager -f to see all the logs without paging and following the running logs persist logs by making changes here /etc/systemd/journald.conf","title":"journalctl"},{"location":"pdf/","text":"Links to PDFs to be referenced CKAD","title":"Links to PDFs to be referenced"},{"location":"pdf/#links-to-pdfs-to-be-referenced","text":"CKAD","title":"Links to PDFs to be referenced"},{"location":"web-conecpts/","text":"Web Concepts Here I will again practice creating a website using the latest technology with mobile native application and containerized backend, I just hope to keep the steam till the end this time :) Starting with creating a personal blog --> Later will make it informational for any mid level software engineer to level up few topics needed for 1. Mobile apps 2. Websites 3. AI/ML application 4. Cloud Native backend 5. De-coupled code. 6. Not much emphasis on beauty for now, just a working model but with all the extendable tech and build anywhere deploy everywhere. SSL Certificates for website Certbot Certbot is used to create letsencrypt certificates for websites certbot certonly \\ -d singhjee.in \\ --logs-dir /home/centos/letsencrypt/log/ \\ --config-dir /home/centos/letsencrypt/config/ \\ --work-dir /home/centos/letsencrypt/work/ \\ -m myemail@gmail.com \\ --agree-tos --manual --preferred-challenges dns","title":"Web Concepts"},{"location":"web-conecpts/#web-concepts","text":"Here I will again practice creating a website using the latest technology with mobile native application and containerized backend, I just hope to keep the steam till the end this time :) Starting with creating a personal blog --> Later will make it informational for any mid level software engineer to level up few topics needed for 1. Mobile apps 2. Websites 3. AI/ML application 4. Cloud Native backend 5. De-coupled code. 6. Not much emphasis on beauty for now, just a working model but with all the extendable tech and build anywhere deploy everywhere.","title":"Web Concepts"},{"location":"web-conecpts/#ssl-certificates-for-website","text":"","title":"SSL Certificates for website"},{"location":"web-conecpts/#certbot","text":"Certbot is used to create letsencrypt certificates for websites certbot certonly \\ -d singhjee.in \\ --logs-dir /home/centos/letsencrypt/log/ \\ --config-dir /home/centos/letsencrypt/config/ \\ --work-dir /home/centos/letsencrypt/work/ \\ -m myemail@gmail.com \\ --agree-tos --manual --preferred-challenges dns","title":"Certbot"}]}