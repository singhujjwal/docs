{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Learn Cloud and Devops tools and tricks This will be constantly updated with the things I keep learning everyday Topics DevOps - DevOps Generic stuffs k8s - Kubernetes Concepts Linux - Linux Administration Web - Web Development About Me Other stuffs","title":"Home"},{"location":"#welcome-to-learn-cloud-and-devops-tools-and-tricks","text":"This will be constantly updated with the things I keep learning everyday","title":"Welcome to Learn Cloud and Devops tools and tricks"},{"location":"#topics","text":"DevOps - DevOps Generic stuffs k8s - Kubernetes Concepts Linux - Linux Administration Web - Web Development","title":"Topics"},{"location":"#about-me","text":"","title":"About Me"},{"location":"#other-stuffs","text":"","title":"Other stuffs"},{"location":"aws/","text":"Services Compute EC2 is the compute service on AWS Storage SOFTNAS usage on AWS Role is very important and the policy { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"aws-marketplace:MeterUsage\", \"ec2:ModifyInstanceAttribute\", \"ec2:DescribeInstances\", \"ec2:CreateVolume\", \"ec2:DeleteVolume\", \"ec2:CreateSnapshot\", \"ec2:DeleteSnapshot\", \"ec2:CreateTags\", \"ec2:DeleteTags\", \"ec2:AttachVolume\", \"ec2:DetachVolume\", \"ec2:DescribeInstances\", \"ec2:DescribeVolumes\", \"ec2:DescribeSnapshots\", \"ec2:DescribeRouteTables\", \"ec2:DescribeAddresses\", \"ec2:DescribeTags\", \"ec2:DescribeInstances\", \"ec2:ModifyNetworkInterfaceAttribute\", \"ec2:ReplaceRoute\", \"ec2:CreateRoute\", \"ec2:DeleteRoute\", \"ec2:AssociateAddress\", \"ec2:DisassociateAddress\", \"s3:CreateBucket\", \"s3:Delete*\", \"s3:Get*\", \"s3:List*\", \"s3:Put*\" ], \"Resource\": \"*\" } ] }","title":"AWS"},{"location":"aws/#services","text":"","title":"Services"},{"location":"aws/#compute","text":"EC2 is the compute service on AWS","title":"Compute"},{"location":"aws/#storage","text":"","title":"Storage"},{"location":"aws/#softnas-usage-on-aws","text":"Role is very important and the policy { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"aws-marketplace:MeterUsage\", \"ec2:ModifyInstanceAttribute\", \"ec2:DescribeInstances\", \"ec2:CreateVolume\", \"ec2:DeleteVolume\", \"ec2:CreateSnapshot\", \"ec2:DeleteSnapshot\", \"ec2:CreateTags\", \"ec2:DeleteTags\", \"ec2:AttachVolume\", \"ec2:DetachVolume\", \"ec2:DescribeInstances\", \"ec2:DescribeVolumes\", \"ec2:DescribeSnapshots\", \"ec2:DescribeRouteTables\", \"ec2:DescribeAddresses\", \"ec2:DescribeTags\", \"ec2:DescribeInstances\", \"ec2:ModifyNetworkInterfaceAttribute\", \"ec2:ReplaceRoute\", \"ec2:CreateRoute\", \"ec2:DeleteRoute\", \"ec2:AssociateAddress\", \"ec2:DisassociateAddress\", \"s3:CreateBucket\", \"s3:Delete*\", \"s3:Get*\", \"s3:List*\", \"s3:Put*\" ], \"Resource\": \"*\" } ] }","title":"SOFTNAS usage on AWS"},{"location":"azure/","text":"AZURE Account and Subscription Your company has an account and you get access to the portal.azure.com but if you don't have a subscription, you can't do anything. In that case either you need to be assigned to a subscription or a tenant or you should have an owner role to create a subscription in that account. The account can be alternatively be called as tenant. Here is a link that describe all types of roles in Azure Directory -> tenant -> Subscriptions (I see one subscription in one directory account is company account) This defines a role is constructed using json, the similar way AWS IAM policies work. Policies link","title":"Azure"},{"location":"azure/#azure","text":"","title":"AZURE"},{"location":"azure/#account-and-subscription","text":"Your company has an account and you get access to the portal.azure.com but if you don't have a subscription, you can't do anything. In that case either you need to be assigned to a subscription or a tenant or you should have an owner role to create a subscription in that account. The account can be alternatively be called as tenant. Here is a link that describe all types of roles in Azure Directory -> tenant -> Subscriptions (I see one subscription in one directory account is company account) This defines a role is constructed using json, the similar way AWS IAM policies work.","title":"Account and Subscription"},{"location":"azure/#policies-link","text":"","title":"Policies link"},{"location":"containers/","text":"Containers Docker Containerd rocket Container Runtime OCI Open Container Interface - Standard for containers Docker containerd(image management)-runc(runtime management) docker daemon -> containerd -> runc In K8s how docker and containerd works kubelet <-CRI-> docker shim <-> docker <-> containerd <-> runc <-> container(s) kubelet <-CRI-> cri-containerd <-> containerd <-> runc <-> container(s) containerd - push and pull images - manage storage - define networks - managing lifecycle of running containers by passing commands to runc runc - also known as libcontainer - low level run time - Rocket (rkt) -- Dead Linux containers (lxc & lxd) VE vs VM running directly on the host VM More reading","title":"Containers"},{"location":"containers/#containers","text":"Docker Containerd rocket Container Runtime OCI Open Container Interface - Standard for containers","title":"Containers"},{"location":"containers/#docker","text":"containerd(image management)-runc(runtime management) docker daemon -> containerd -> runc In K8s how docker and containerd works kubelet <-CRI-> docker shim <-> docker <-> containerd <-> runc <-> container(s) kubelet <-CRI-> cri-containerd <-> containerd <-> runc <-> container(s) containerd - push and pull images - manage storage - define networks - managing lifecycle of running containers by passing commands to runc runc - also known as libcontainer - low level run time - Rocket (rkt) -- Dead Linux containers (lxc & lxd) VE vs VM running directly on the host VM More reading","title":"Docker"},{"location":"interviewquestions/","text":"Interview questions What is DevOps how do you devops ? What is a microservice and what are the advantages of it over monolithic Why REST ? How streaming services works design a messaging system.","title":"Interview"},{"location":"interviewquestions/#interview-questions","text":"What is DevOps how do you devops ? What is a microservice and what are the advantages of it over monolithic Why REST ? How streaming services works design a messaging system.","title":"Interview questions"},{"location":"k8s/","text":"Kubernetes Concepts Concepts K8s objects are record of intent. Once you create it the kubernetes system takes care of making sure it is running all the time. Object spec: What is constitutes Object Status: Makes sure the status of the objects remains the same as defined in the status. Pod A pod represents a running process on your system sharing the same network (port and ip), storage. A pod enacapsulates an applicaton running in one or more containers, pods itself doesn\u2019t heal, will need a deployment to get the self healing capability. Services A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them - sometimes called a micro-service. The set of Pods targeted by a Service is (usually) determined by a Label Selector. Kubernetes also supports DNS SRV (service) records for named ports. If the \"my-service.my-ns\" Service has a port named \"http\" with protocol TCP, you can do a DNS SRV query for \"_http._tcp.my-service.my-ns\" to discover the port number for \"http\". The Kubernetes DNS server is the only way to access services of type ExternalName Kubernetes ServiceTypes allow you to specify what kind of service you want. The default is ClusterIP. Type values and their behaviors are: ClusterIP: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. This is the default ServiceType. NodePort: Exposes the service on each Node\u2019s IP at a static port (the NodePort). A ClusterIP service, to which the NodePort service will route, is automatically created. You\u2019ll be able to contact the NodePort service, from outside the cluster, by requesting : . LoadBalancer: Exposes the service externally using a cloud provider\u2019s load balancer. NodePort and ClusterIP services, to which the external load balancer will route, are automatically created. ExternalName: Maps the service to the contents of the externalName field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up. This requires version 1.7 or higher of kube-dns. Volumes Types of volumes * Local * EBS * azureDisk * azureFile * configMap * emptyDir * hostPath * local * nfs * persistentVolumeClaim Example of AWS EBS 1. Create a volume first in the same zone as the node is present using command aws ec2 create-volume --availability-zone=eu-west-1a --size=10 --volume-type=gp2 2. Use the below YAML to provide and ebs volume to a pod apiVersion: v1 kind: Pod metadata: name: test-ebs spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-ebs name: test-volume volumes: - name: test-volume # This AWS EBS volume must already exist. awsElasticBlockStore: volumeID: <volume-id> fsType: ext4 configMap is one of the very frequently used volume which is basically a key value store details apiVersion: v1 kind: Pod metadata: name: configmap-pod spec: containers: - name: test image: busybox volumeMounts: - name: config-vol mountPath: /etc/config volumes: - name: config-vol configMap: name: log-config items: - key: log_level path: log_level projected : A projected volume maps several existing volume sources into the same directory. e.g. Persistent Volume A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system. Persistent Volume Claim A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted once read/write or many times read-only). It can be static of dynamic, if a cluster admin has not created a PV explicitly a dynamic PV is created when a PVC is requested. Storage Class Ingress NGINX Ingress controller Exposing TCP port You can expose a TCP port from an ingress-controller directly to outside world. It can be done by installing nginx with a nginx-ingress-tcp config map. It gets created and USED only when is nginx is installed or upgraded # TBD come and revisit so do a helm install --set tcp.9000=\"plat-system/tcp-echo:9000\" with this or else helm upgrade with all existing options and the above. After that patch the configmap and the nginx service ConfigMap as configmap.yaml data: \"31000\": namespace/service:31000 kubectl patch configmaps nginx-ingress-tcp --namespace namespace --patch \"$(cat configmap.yaml)\" Service patch as service.yaml spec: ports: - name: service-31000 port: 31000 protocol: TCP targetPort: 31000 As you can see name service-31000 doesn't matter. kubectl patch services nginx-ingress-controller --namespace namespace --patch \"$(cat service.yaml)\"","title":"K8S Concepts"},{"location":"k8s/#kubernetes-concepts","text":"","title":"Kubernetes Concepts"},{"location":"k8s/#concepts","text":"K8s objects are record of intent. Once you create it the kubernetes system takes care of making sure it is running all the time. Object spec: What is constitutes Object Status: Makes sure the status of the objects remains the same as defined in the status.","title":"Concepts"},{"location":"k8s/#pod","text":"A pod represents a running process on your system sharing the same network (port and ip), storage. A pod enacapsulates an applicaton running in one or more containers, pods itself doesn\u2019t heal, will need a deployment to get the self healing capability.","title":"Pod"},{"location":"k8s/#services","text":"A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them - sometimes called a micro-service. The set of Pods targeted by a Service is (usually) determined by a Label Selector. Kubernetes also supports DNS SRV (service) records for named ports. If the \"my-service.my-ns\" Service has a port named \"http\" with protocol TCP, you can do a DNS SRV query for \"_http._tcp.my-service.my-ns\" to discover the port number for \"http\". The Kubernetes DNS server is the only way to access services of type ExternalName Kubernetes ServiceTypes allow you to specify what kind of service you want. The default is ClusterIP. Type values and their behaviors are: ClusterIP: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. This is the default ServiceType. NodePort: Exposes the service on each Node\u2019s IP at a static port (the NodePort). A ClusterIP service, to which the NodePort service will route, is automatically created. You\u2019ll be able to contact the NodePort service, from outside the cluster, by requesting : . LoadBalancer: Exposes the service externally using a cloud provider\u2019s load balancer. NodePort and ClusterIP services, to which the external load balancer will route, are automatically created. ExternalName: Maps the service to the contents of the externalName field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up. This requires version 1.7 or higher of kube-dns.","title":"Services"},{"location":"k8s/#volumes","text":"Types of volumes * Local * EBS * azureDisk * azureFile * configMap * emptyDir * hostPath * local * nfs * persistentVolumeClaim Example of AWS EBS 1. Create a volume first in the same zone as the node is present using command aws ec2 create-volume --availability-zone=eu-west-1a --size=10 --volume-type=gp2 2. Use the below YAML to provide and ebs volume to a pod apiVersion: v1 kind: Pod metadata: name: test-ebs spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-ebs name: test-volume volumes: - name: test-volume # This AWS EBS volume must already exist. awsElasticBlockStore: volumeID: <volume-id> fsType: ext4 configMap is one of the very frequently used volume which is basically a key value store details apiVersion: v1 kind: Pod metadata: name: configmap-pod spec: containers: - name: test image: busybox volumeMounts: - name: config-vol mountPath: /etc/config volumes: - name: config-vol configMap: name: log-config items: - key: log_level path: log_level projected : A projected volume maps several existing volume sources into the same directory. e.g.","title":"Volumes"},{"location":"k8s/#persistent-volume","text":"A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.","title":"Persistent Volume"},{"location":"k8s/#persistent-volume-claim","text":"A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted once read/write or many times read-only). It can be static of dynamic, if a cluster admin has not created a PV explicitly a dynamic PV is created when a PVC is requested.","title":"Persistent Volume Claim"},{"location":"k8s/#storage-class","text":"","title":"Storage Class"},{"location":"k8s/#ingress","text":"","title":"Ingress"},{"location":"k8s/#nginx-ingress-controller","text":"","title":"NGINX Ingress controller"},{"location":"k8s/#exposing-tcp-port","text":"You can expose a TCP port from an ingress-controller directly to outside world. It can be done by installing nginx with a nginx-ingress-tcp config map. It gets created and USED only when is nginx is installed or upgraded # TBD come and revisit so do a helm install --set tcp.9000=\"plat-system/tcp-echo:9000\" with this or else helm upgrade with all existing options and the above. After that patch the configmap and the nginx service ConfigMap as configmap.yaml data: \"31000\": namespace/service:31000 kubectl patch configmaps nginx-ingress-tcp --namespace namespace --patch \"$(cat configmap.yaml)\" Service patch as service.yaml spec: ports: - name: service-31000 port: 31000 protocol: TCP targetPort: 31000 As you can see name service-31000 doesn't matter. kubectl patch services nginx-ingress-controller --namespace namespace --patch \"$(cat service.yaml)\"","title":"Exposing TCP port"},{"location":"k8sadmin/","text":"Commands Print the kubelet joinging command: sudo kubeadm token create --print-join-command kubelet reset # to reset a node joined to a master, also from master it can be deleted like kubectl delete node https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/ kubectl port-forward pods/redis-master-765d459796-258hz 6379:6379 or kubectl port-forward deployment/redis-master 6379:6379 or kubectl port-forward rs/redis-master 6379:6379 or kubectl port-forward svc/redis-master 6379:6379 Command to set default storage class to local-path kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' K8s Install on CENTOS sudo swapoff -a sudo vi /etc/fstab sudo yum -y install docker sudo systemctl enable docker sudo systemctl start docker cat << EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo setenforce 0 sudo vi /etc/selinux/config # Change to permissive sudo yum install -y kubelet kubeadm kubectl sudo systemctl enable kubelet sudo systemctl start kubelet cat << EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system #Only on master sudo kubeadm init --pod-network-cidr=10.244.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml # only on worker nodes sudo kubeadm join $controller_private_ip:6443 --token $token --discovery-token-ca-cert-hash $hash sudo kubeadm join 172.31.100.147:6443 --token w28oiv.2dx6buwbj400mc4x --discovery-token-ca-cert-hash sha256:ed0e354f71183a76cbb58166d5d710b3b39e343c253ee232509ce5f412d05b3a kubectl get nodes Helm Package manager for kubernetes Helm runs with \"default\" service account. You should provide permissions to it. For read permissions: kubectl create rolebinding default-view --clusterrole=view --serviceaccount=kube-system:default --namespace=kube-system For admin permissions: kubectl create clusterrolebinding add-on-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default More details here https://stackoverflow.com/questions/46672523/helm-list-cannot-list-configmaps-in-the-namespace-kube-system Cert-Manager Cert manager is a very important package for generating certs for applications in k8s. DNS01 challenge are very helpful in creating wildcard certificates, also http01 challenges are good when you want just few certs There are many gotchas and need to have either a role, cross account role for AWS For azure use the service principal. Also for split horizon dns cert-manager can be run using parameter extraArgs={--dns01-recursive-nameservers \"8.8.8.8:53,1.1.1.1:53\"} https://cert-manager.io/docs/configuration/acme/dns01/ Steps to use cert-manager 1. Install cert-manager CRDS 2. Install cert-manager with the extra dns options in case of split horizon or delegated DNS 3. Create a certificate issuer in cert-manager namespace based on the CRD apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-staging namespace: cert-manager spec: acme: # server: https://acme-staging-v02.api.letsencrypt.org/directory server: https://acme-v02.api.letsencrypt.org/directory email: ujjwal.singh@example.com privateKeySecretRef: name: letsencrypt-staging solvers: - selector: dnsZones: - \"tenant1.example.com\" dns01: route53: region: us-east-1 hostedZoneID: xxxxxxxxxxxx role: 'arn:aws:iam::xxxxxxxxxx:role/Role-DNS-STS' Create the certificate in the namespace where you want to use the tls secret, else you need to copy the tls secret to all the namespaces if the ingress needs to be created in another namespace apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: lets-encrypt-cert namespace: ict spec: commonName: 'ujjwal.tenant1.example.com' dnsNames: - '*.ujjwal.tenant1.example.com' - 'ujjwal.tenant1.example.com' issuerRef: kind: ClusterIssuer name: letsencrypt-staging secretName: letsencrypt-staging-cert-secret Create an ingress which loads the tls certs apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress namespace: ict annotations: kubernetes.io/ingress.class: traefik spec: tls: - secretName: letsencrypt-staging-cert-secret rules: - host: ujjwal.tenant1.example.com http: paths: - path: /awx backend: serviceName: awx servicePort: 8052 # The node port You can use https://github.com/mittwald/kubernetes-replicator for replicating secrets across namespaces.","title":"K8S Administraton"},{"location":"k8sadmin/#commands","text":"Print the kubelet joinging command: sudo kubeadm token create --print-join-command kubelet reset # to reset a node joined to a master, also from master it can be deleted like kubectl delete node https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/ kubectl port-forward pods/redis-master-765d459796-258hz 6379:6379 or kubectl port-forward deployment/redis-master 6379:6379 or kubectl port-forward rs/redis-master 6379:6379 or kubectl port-forward svc/redis-master 6379:6379 Command to set default storage class to local-path kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'","title":"Commands"},{"location":"k8sadmin/#k8s-install-on-centos","text":"sudo swapoff -a sudo vi /etc/fstab sudo yum -y install docker sudo systemctl enable docker sudo systemctl start docker cat << EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo setenforce 0 sudo vi /etc/selinux/config # Change to permissive sudo yum install -y kubelet kubeadm kubectl sudo systemctl enable kubelet sudo systemctl start kubelet cat << EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system #Only on master sudo kubeadm init --pod-network-cidr=10.244.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml # only on worker nodes sudo kubeadm join $controller_private_ip:6443 --token $token --discovery-token-ca-cert-hash $hash sudo kubeadm join 172.31.100.147:6443 --token w28oiv.2dx6buwbj400mc4x --discovery-token-ca-cert-hash sha256:ed0e354f71183a76cbb58166d5d710b3b39e343c253ee232509ce5f412d05b3a kubectl get nodes","title":"K8s Install on CENTOS"},{"location":"k8sadmin/#helm","text":"Package manager for kubernetes Helm runs with \"default\" service account. You should provide permissions to it. For read permissions: kubectl create rolebinding default-view --clusterrole=view --serviceaccount=kube-system:default --namespace=kube-system For admin permissions: kubectl create clusterrolebinding add-on-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default More details here https://stackoverflow.com/questions/46672523/helm-list-cannot-list-configmaps-in-the-namespace-kube-system","title":"Helm"},{"location":"k8sadmin/#cert-manager","text":"Cert manager is a very important package for generating certs for applications in k8s. DNS01 challenge are very helpful in creating wildcard certificates, also http01 challenges are good when you want just few certs There are many gotchas and need to have either a role, cross account role for AWS For azure use the service principal. Also for split horizon dns cert-manager can be run using parameter extraArgs={--dns01-recursive-nameservers \"8.8.8.8:53,1.1.1.1:53\"} https://cert-manager.io/docs/configuration/acme/dns01/ Steps to use cert-manager 1. Install cert-manager CRDS 2. Install cert-manager with the extra dns options in case of split horizon or delegated DNS 3. Create a certificate issuer in cert-manager namespace based on the CRD apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-staging namespace: cert-manager spec: acme: # server: https://acme-staging-v02.api.letsencrypt.org/directory server: https://acme-v02.api.letsencrypt.org/directory email: ujjwal.singh@example.com privateKeySecretRef: name: letsencrypt-staging solvers: - selector: dnsZones: - \"tenant1.example.com\" dns01: route53: region: us-east-1 hostedZoneID: xxxxxxxxxxxx role: 'arn:aws:iam::xxxxxxxxxx:role/Role-DNS-STS' Create the certificate in the namespace where you want to use the tls secret, else you need to copy the tls secret to all the namespaces if the ingress needs to be created in another namespace apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: lets-encrypt-cert namespace: ict spec: commonName: 'ujjwal.tenant1.example.com' dnsNames: - '*.ujjwal.tenant1.example.com' - 'ujjwal.tenant1.example.com' issuerRef: kind: ClusterIssuer name: letsencrypt-staging secretName: letsencrypt-staging-cert-secret Create an ingress which loads the tls certs apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress namespace: ict annotations: kubernetes.io/ingress.class: traefik spec: tls: - secretName: letsencrypt-staging-cert-secret rules: - host: ujjwal.tenant1.example.com http: paths: - path: /awx backend: serviceName: awx servicePort: 8052 # The node port You can use https://github.com/mittwald/kubernetes-replicator for replicating secrets across namespaces.","title":"Cert-Manager"},{"location":"lin_command/","text":"Linux Debugging Linux debugging is nothing without knowing the right commands. That too in quick time. Debugging Linux falls into various categories * System diagnostics: Devices, CPU, memory, IO, networking * Logs * Processes * Inspecting filesystem and open files * Sockets and networking * System Diagonostics top mpstat Logs There are various log files generated in Linux system which will help debugging the errors. journalctl journalctl is a command for viewing logs collected by systemd. The systemd-journald service is responsible for systemd\u2019s log collection, and it retrieves messages from the kernel, systemd services, and other sources. journalctl -r journalctl -u telegraf --no-pager -f to see all the logs without paging and following the running logs persist logs by making changes here /etc/systemd/journald.conf","title":"Linux Debugging"},{"location":"lin_command/#linux-debugging","text":"Linux debugging is nothing without knowing the right commands. That too in quick time. Debugging Linux falls into various categories * System diagnostics: Devices, CPU, memory, IO, networking * Logs * Processes * Inspecting filesystem and open files * Sockets and networking *","title":"Linux Debugging"},{"location":"lin_command/#system-diagonostics","text":"top mpstat","title":"System Diagonostics"},{"location":"lin_command/#logs","text":"There are various log files generated in Linux system which will help debugging the errors.","title":"Logs"},{"location":"lin_command/#journalctl","text":"journalctl is a command for viewing logs collected by systemd. The systemd-journald service is responsible for systemd\u2019s log collection, and it retrieves messages from the kernel, systemd services, and other sources. journalctl -r journalctl -u telegraf --no-pager -f to see all the logs without paging and following the running logs persist logs by making changes here /etc/systemd/journald.conf","title":"journalctl"},{"location":"linux/","text":"COMMON Commands Update code present Command to pull all the code from master branch in all the subdirectories in a code folder for d in $(find -maxdepth 1 -type d) do pushd $d git pull popd done Centos Mounting NFS volumes mount -o rsize=32768,wsize=32768,noatime,intr <ip-address>:<export-path> <mnt-point> mkdir /mnt/myvol01 mount -o rsize=32768,wsize=32768,noatime,intr 10.22.197.195:/export/pool1/ujjwalvol /mnt/vol01 Make entry in /etc/fstab for permanent 10.22.197.195:/export/pool1/ujjwalvol /mnt/vol01 nfs rw,hard,intr,rsize=32768,wsize=32768,timeo=14 0 0 After making changes in /etc/fstab need to mount the directory as mount /mnt/vol01/ and you don't need to restart the machine neither nfs not linux Common NFS Issues The most common issue encountered when mounting and using an NFS volume are Access Denied and read-only types of problems. Access Denied - This typically happens when trying to mount an NFS export that has been restricted by IP address range, user ID or other permission restrictions. Try opening up the NFS export for access by any IP address and Everyone; i.e., loosen the security up during initial testing, then lock it back down one step at a time. Read-Only Access - When this happens, it is possible to mount the filesystem, but not possible to write to the mounted filesystem. This is a security permissions issue. Try opening up the permissions on the NFS export to Everyone as a starting point, then with a working NFS mount, choose to lock the security down incrementally. Ubuntu Setting proxy in ubuntu for update cat /etc/apt/apt.conf Acquire::http::Proxy \"http://proxy.example.com:80\"; Acquire::ftp::Proxy \"https://proxy.example.com:80\"; Acquire::https::Proxy \"http://proxy.example.com:80\"; Troubleshooting Networking use either telent or ncat nc -vvvzw1 google.com 443 wget https://github.com/tmate-io/tmate/releases/download/2.4.0/tmate-2.4.0-static-linux-amd64.tar.xz chmod +x ./tmate xz -cd te-2.4.0-static-linux-amd64.tar.xz | t ./tmate -F","title":"Linux"},{"location":"linux/#common","text":"","title":"COMMON"},{"location":"linux/#commands","text":"","title":"Commands"},{"location":"linux/#update-code-present","text":"Command to pull all the code from master branch in all the subdirectories in a code folder for d in $(find -maxdepth 1 -type d) do pushd $d git pull popd done","title":"Update code present"},{"location":"linux/#centos","text":"","title":"Centos"},{"location":"linux/#mounting-nfs-volumes","text":"mount -o rsize=32768,wsize=32768,noatime,intr <ip-address>:<export-path> <mnt-point> mkdir /mnt/myvol01 mount -o rsize=32768,wsize=32768,noatime,intr 10.22.197.195:/export/pool1/ujjwalvol /mnt/vol01 Make entry in /etc/fstab for permanent 10.22.197.195:/export/pool1/ujjwalvol /mnt/vol01 nfs rw,hard,intr,rsize=32768,wsize=32768,timeo=14 0 0 After making changes in /etc/fstab need to mount the directory as mount /mnt/vol01/ and you don't need to restart the machine neither nfs not linux Common NFS Issues The most common issue encountered when mounting and using an NFS volume are Access Denied and read-only types of problems. Access Denied - This typically happens when trying to mount an NFS export that has been restricted by IP address range, user ID or other permission restrictions. Try opening up the NFS export for access by any IP address and Everyone; i.e., loosen the security up during initial testing, then lock it back down one step at a time. Read-Only Access - When this happens, it is possible to mount the filesystem, but not possible to write to the mounted filesystem. This is a security permissions issue. Try opening up the permissions on the NFS export to Everyone as a starting point, then with a working NFS mount, choose to lock the security down incrementally.","title":"Mounting NFS volumes"},{"location":"linux/#ubuntu","text":"","title":"Ubuntu"},{"location":"linux/#setting-proxy-in-ubuntu-for-update","text":"cat /etc/apt/apt.conf Acquire::http::Proxy \"http://proxy.example.com:80\"; Acquire::ftp::Proxy \"https://proxy.example.com:80\"; Acquire::https::Proxy \"http://proxy.example.com:80\";","title":"Setting proxy in ubuntu for update"},{"location":"linux/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"linux/#networking","text":"use either telent or ncat nc -vvvzw1 google.com 443 wget https://github.com/tmate-io/tmate/releases/download/2.4.0/tmate-2.4.0-static-linux-amd64.tar.xz chmod +x ./tmate xz -cd te-2.4.0-static-linux-amd64.tar.xz | t ./tmate -F","title":"Networking"},{"location":"pdf/","text":"CKAD","title":"PDFs"}]}